# -*- coding: utf-8 -*-
"""MNIST-XGBoost

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NXBm5PxAnIlLPGcMbzVuZm-JXZjhcmm-


import torchvision
import torch
import matplotlib.pyplot as plt
import numpy as np
import xgboost as xgb
from sklearn import metrics


# 读取训练和测试数据集
train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True)
test_set = torchvision.datasets.MNIST(root='./data', train=False)


# 超参
sap_img = train_set[0][0]
img_square = sap_img.size[0] * sap_img.size[1]    #计算图片像素点个数
   

def img2vector(img):
    imge = np.array(img, dtype=np.uint8)   #将PIL.Image的image类型转为ndarray
    vector = imge.flatten()         #扁平化为1维向量
    return vector


def readData(dataset):     
    numImgs = len(dataset)      #统计需要读取的图片的数目
    ImgData = np.zeros([numImgs, img_square],int)    #用于存放所有的扁平化后的图片
    labels = np.zeros([numImgs])     #用于存放对应的标签(与神经网络的不同)
    for i in range(numImgs):      #遍历所有的图片
        image = dataset[i][0]
        digit = int(dataset[i][1])
        #labels[i][digit] = 1.0        #将数字标签转换为one-hot编码
        labels[i] = digit          #不使用one-hot编码
        ImgData[i] = img2vector(image)        #读取图片内容 
    return ImgData,labels


# 加载图片数据与类标签
X_train, Y_train = readData(train_set)
X_test, Y_test = readData(test_set)


# 模型的构建和训练
model = xgb.XGBClassifier(learning_rate = 0.05,
    max_depth = 5,
    objective = 'multi:softmax',   #指定softmax损失函数
    num_class = 10,         #指定多分类数
    gamma = 0.1,       #用于指定节点分割所需的最小损失函数下降值，即增益值Gain的阈值
    reg_lambda = 1.5,     #L2正则化率
    min_child_weight = 2,   #用于指定叶子节点中各样本点二阶导之和的最小值，默认为1，该参数的值越小，模型越容易过拟合
    n_jobs = 8)
model.fit(X_train, Y_train)
predict = model.predict(X_test)

# 模型评估
print('测试准确率为：',metrics.accuracy_score(Y_test, predict))